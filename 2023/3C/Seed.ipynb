{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c12a54e1-a302-45ae-b8d2-dd93d7e38799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import sampler\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import methodtools\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import pickle\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9596fca8-6471-45ef-85f7-be4918da80d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BeitFeatureExtractor, BeitForMaskedImageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7a5cf57e-b5f0-46c4-b605-09f56358fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantSeedlingDataset(Dataset):\n",
    "    def __init__(self, root_dir, train=True):\n",
    "        self.train = train\n",
    "        self.root_dir = root_dir\n",
    "        self.labels = [dir for dir in os.listdir(root_dir) if dir != 'encoding']\n",
    "        self.label_map = {label: i for i, label in enumerate(self.labels)}\n",
    "        self.feature_extractor = \\\n",
    "            BeitFeatureExtractor.from_pretrained('microsoft/beit-large-patch16-224-pt22k')\n",
    "        self.bert_model = \\\n",
    "            BeitForMaskedImageModeling.from_pretrained('microsoft/beit-large-patch16-224-pt22k')\n",
    "        \n",
    "        images_with_label = []\n",
    "        for label in self.labels:\n",
    "            label_id = self.label_map[label]\n",
    "            for image in os.listdir(os.path.join(root_dir, label)):\n",
    "                images_with_label.append((image, label_id))\n",
    "        \n",
    "        random.seed(42)\n",
    "        random.shuffle(images_with_label)\n",
    "        self.images = images_with_label\n",
    "        \n",
    "        self.encoding_dir = os.path.join(root_dir, 'encoding')\n",
    "        pathlib.Path(self.encoding_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for name, label in self.images:\n",
    "            if os.path.isfile(os.path.join(self.encoding_dir, f'{name}.pt')):\n",
    "                continue\n",
    "            print(f\"Processing {self.labels[label]}/{name}...\")\n",
    "            image = Image.open(os.path.join(self.root_dir, self.labels[label], name))\n",
    "            image = TF.to_tensor(image)\n",
    "            if image.shape[0] > 3:\n",
    "                image = image[:3, :, :]\n",
    "            image = TF.resize(image, (224, 224))\n",
    "            image = TF.normalize(image, (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            inputs = self.feature_extractor(images=image, return_tensors=\"pt\")\n",
    "            outputs = self.bert_model(**inputs)\n",
    "            encoding = torch.tensor(outputs.logits, dtype=torch.bfloat16)\n",
    "            torch.save(encoding, os.path.join(self.encoding_dir, f'{name}.pt'))        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        name, label_id = self.images[idx]\n",
    "        encoding = torch.load(os.path.join(self.encoding_dir, f'{name}.pt'))\n",
    "        return {'encoding': encoding, 'label': label_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db8e6f92-aae6-481b-8b63-34ed9d32f5fe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = PlantSeedlingDataset(\"data/plant-seedling-raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0b4b37bb-3d37-43f6-ab88-d10dafb80765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4750"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f9913a01-129a-43a5-88fb-001d840d0a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start = 0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "NUM_TRAIN = 4000\n",
    "NUM_VAL = 750\n",
    "loader_train = DataLoader(ds, batch_size=32, sampler=ChunkSampler(NUM_TRAIN, 0))\n",
    "loader_val = DataLoader(ds, batch_size=32, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad5184a2-508d-49a8-924e-5054d96568c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=1605632, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = torch.BFloat16Tensor\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(), # see above for explanation\n",
    "    nn.Linear(np.prod(list(ds[0]['encoding'].shape)), len(ds.labels)), # affine layer\n",
    ")\n",
    "\n",
    "model.type(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "659f6977-c6b7-4f3f-a84f-7587d95bfc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_dtype = torch.cuda.BFloat16Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e355d8b-e323-4c83-8e44-714eb7074111",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 25\n",
    "\n",
    "def train(model, loss_fn, optimizer, num_epochs = 1):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "        model.train()\n",
    "        for t, data in enumerate(loader_train):\n",
    "            x_var = Variable(data['encoding']).to(\"cuda\")\n",
    "            y_var = Variable(data['label']).to(\"cuda\")\n",
    "            scores = model(x_var)\n",
    "            loss = loss_fn(scores, y_var)\n",
    "            if (t + 1) % print_every == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.item()))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f14b5312-7fcf-48c4-a1bb-dfd6b06a95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def check_accuracy(model, loader):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    for data in loader:\n",
    "        x_var = Variable(data['encoding']).to(\"cuda\")\n",
    "        y_var = Variable(data['label'])\n",
    "\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        num_correct += (preds == y_var).sum()\n",
    "        num_samples += preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a97cb46-ceca-4b00-bbeb-f21a026a871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3) \n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "65634765-37bd-4316-b334-1dc75feaf934",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "457ec971-2896-4875-95b8-fea5573647ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1 / 1\n",
      "t = 25, loss = 44.0000\n",
      "t = 50, loss = 336.0000\n",
      "t = 75, loss = 188.0000\n",
      "t = 100, loss = 360.0000\n",
      "t = 125, loss = 412.0000\n",
      "Checking accuracy on validation set\n",
      "Got 338 / 750 correct (45.07)\n",
      "Starting epoch 1 / 1\n",
      "t = 25, loss = 568.0000\n",
      "t = 50, loss = 480.0000\n",
      "t = 75, loss = 155.0000\n",
      "t = 100, loss = 412.0000\n",
      "t = 125, loss = 328.0000\n",
      "Checking accuracy on validation set\n",
      "Got 418 / 750 correct (55.73)\n",
      "Starting epoch 1 / 1\n",
      "t = 25, loss = 101.0000\n",
      "t = 50, loss = 260.0000\n",
      "t = 75, loss = 62.0000\n",
      "t = 100, loss = 298.0000\n",
      "t = 125, loss = 106.0000\n",
      "Checking accuracy on validation set\n",
      "Got 435 / 750 correct (58.00)\n",
      "Starting epoch 1 / 1\n",
      "t = 25, loss = 39.0000\n",
      "t = 50, loss = 96.0000\n",
      "t = 75, loss = 128.0000\n",
      "t = 100, loss = 53.0000\n",
      "t = 125, loss = 72.0000\n",
      "Checking accuracy on validation set\n",
      "Got 461 / 750 correct (61.47)\n",
      "Starting epoch 1 / 1\n",
      "t = 25, loss = 54.0000\n",
      "t = 50, loss = 110.0000\n",
      "t = 75, loss = 39.0000\n",
      "t = 100, loss = 8.0000\n",
      "t = 125, loss = 56.0000\n",
      "Checking accuracy on validation set\n",
      "Got 466 / 750 correct (62.13)\n",
      "Starting epoch 1 / 1\n",
      "t = 25, loss = 22.0000\n",
      "t = 50, loss = 23.0000\n",
      "t = 75, loss = 516.0000\n",
      "t = 100, loss = 22.0000\n",
      "t = 125, loss = 42.0000\n",
      "Checking accuracy on validation set\n",
      "Got 467 / 750 correct (62.27)\n",
      "Starting epoch 1 / 1\n",
      "t = 25, loss = 0.0000\n",
      "t = 50, loss = 0.0000\n",
      "t = 75, loss = 2.0000\n",
      "t = 100, loss = 0.0000\n",
      "t = 125, loss = 0.0000\n",
      "Checking accuracy on validation set\n",
      "Got 477 / 750 correct (63.60)\n",
      "Starting epoch 1 / 1\n",
      "t = 25, loss = 0.0000\n",
      "t = 50, loss = 16.0000\n",
      "t = 75, loss = 0.0000\n",
      "t = 100, loss = 0.0000\n",
      "t = 125, loss = 0.0000\n",
      "Checking accuracy on validation set\n",
      "Got 473 / 750 correct (63.07)\n",
      "Starting epoch 1 / 1\n",
      "t = 25, loss = 0.0000\n",
      "t = 50, loss = 0.0000\n",
      "t = 75, loss = 28.0000\n",
      "t = 100, loss = 0.0000\n",
      "t = 125, loss = 0.0000\n",
      "Checking accuracy on validation set\n",
      "Got 469 / 750 correct (62.53)\n",
      "Starting epoch 1 / 1\n",
      "t = 25, loss = 0.0000\n",
      "t = 50, loss = 20.0000\n",
      "t = 75, loss = 0.0000\n",
      "t = 100, loss = 0.0000\n",
      "t = 125, loss = 0.0000\n",
      "Checking accuracy on validation set\n",
      "Got 485 / 750 correct (64.67)\n",
      "Starting epoch 1 / 1\n",
      "t = 25, loss = 0.0000\n",
      "t = 50, loss = 0.0000\n",
      "t = 75, loss = 0.0000\n",
      "t = 100, loss = 0.0000\n",
      "t = 125, loss = 14.0000\n",
      "Checking accuracy on validation set\n",
      "Got 476 / 750 correct (63.47)\n",
      "Starting epoch 1 / 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [79]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     acc \u001b[38;5;241m=\u001b[39m check_accuracy(model, loader_val)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m acc \u001b[38;5;241m>\u001b[39m best_acc:\n",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader_train):\n\u001b[0;32m----> 8\u001b[0m     x_var \u001b[38;5;241m=\u001b[39m \u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     y_var \u001b[38;5;241m=\u001b[39m Variable(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     scores \u001b[38;5;241m=\u001b[39m model(x_var)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    train(model, loss_fn, optimizer, num_epochs=1)\n",
    "    acc = check_accuracy(model, loader_val)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), \"bert+linear.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f2ba67a-c8ef-4fd6-b30c-8b8b6d7c8396",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantSeedlingTestDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.train = False\n",
    "        self.root_dir = root_dir\n",
    "        self.feature_extractor = \\\n",
    "            BeitFeatureExtractor.from_pretrained('microsoft/beit-large-patch16-224-pt22k')\n",
    "        self.bert_model = \\\n",
    "            BeitForMaskedImageModeling.from_pretrained('microsoft/beit-large-patch16-224-pt22k')\n",
    "        \n",
    "        images = [file for file in os.listdir(self.root_dir) if file != 'encoding']\n",
    "        self.images = images\n",
    "        \n",
    "        self.encoding_dir = os.path.join(root_dir, 'encoding')\n",
    "        pathlib.Path(self.encoding_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for name in self.images:\n",
    "            if os.path.isfile(os.path.join(self.encoding_dir, f'{name}.pt')):\n",
    "                continue\n",
    "            print(f\"Processing {name}...\")\n",
    "            image = Image.open(os.path.join(self.root_dir, name))\n",
    "            image = TF.to_tensor(image)\n",
    "            if image.shape[0] > 3:\n",
    "                image = image[:3, :, :]\n",
    "            image = TF.resize(image, (224, 224))\n",
    "            image = TF.normalize(image, (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            inputs = self.feature_extractor(images=image, return_tensors=\"pt\")\n",
    "            outputs = self.bert_model(**inputs)\n",
    "            encoding = torch.tensor(outputs.logits, dtype=torch.bfloat16)\n",
    "            torch.save(encoding, os.path.join(self.encoding_dir, f'{name}.pt'))        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        encoding = torch.load(os.path.join(self.encoding_dir, f'{self.images[idx]}.pt'))\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e335ff8e-205c-49d5-9641-6370838aa0f2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2053ada02.png...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2316789/1331888548.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  encoding = torch.tensor(outputs.logits, dtype=torch.bfloat16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 917aa970b.png...\n",
      "Processing 46c4aed02.png...\n",
      "Processing 817aacd06.png...\n",
      "Processing 25c8aa30c.png...\n",
      "Processing 3f13ad205.png...\n",
      "Processing adb2a8107.png...\n",
      "Processing b504a070f.png...\n",
      "Processing 71c7ad202.png...\n",
      "Processing 3217a1807.png...\n",
      "Processing a530a8c00.png...\n",
      "Processing e246a570b.png...\n",
      "Processing 05e5a5c06.png...\n",
      "Processing c9f6afa0c.png...\n",
      "Processing 3b5ba1404.png...\n",
      "Processing 1750ad208.png...\n",
      "Processing c621aa904.png...\n",
      "Processing eca8ad508.png...\n",
      "Processing c2c1a8707.png...\n",
      "Processing c395a1d0a.png...\n",
      "Processing ee5ca2c09.png...\n",
      "Processing 62d1a6303.png...\n",
      "Processing c41ba990c.png...\n",
      "Processing 2cb4abe06.png...\n",
      "Processing cfb3a6509.png...\n",
      "Processing caaeac306.png...\n",
      "Processing 28a2a7408.png...\n",
      "Processing 0975a0204.png...\n",
      "Processing ab41ae606.png...\n",
      "Processing 425eab609.png...\n",
      "Processing 5423ad505.png...\n",
      "Processing bee1a8206.png...\n",
      "Processing c5f0adc04.png...\n",
      "Processing fc58a690c.png...\n",
      "Processing 5dfaa9101.png...\n",
      "Processing 7863a4408.png...\n",
      "Processing 3bf4a0c04.png...\n",
      "Processing f5caad402.png...\n",
      "Processing d898a900b.png...\n",
      "Processing 5d82ab10b.png...\n",
      "Processing 3508af302.png...\n",
      "Processing 0372a4801.png...\n",
      "Processing f19ca340e.png...\n",
      "Processing 3ef4a5902.png...\n",
      "Processing 5fa5a3004.png...\n",
      "Processing 9eedac804.png...\n",
      "Processing f1d3a3b02.png...\n",
      "Processing 7cefa6507.png...\n",
      "Processing c068a9f07.png...\n",
      "Processing fb57ae609.png...\n",
      "Processing f567aef05.png...\n",
      "Processing 1a4fa0d06.png...\n",
      "Processing 273fac705.png...\n",
      "Processing 3b24adc0d.png...\n",
      "Processing b026a550c.png...\n",
      "Processing a34aa4800.png...\n",
      "Processing 8738a940a.png...\n",
      "Processing ab78afb06.png...\n",
      "Processing 0e93a4d05.png...\n",
      "Processing 44d5a2402.png...\n",
      "Processing 6334a8b0d.png...\n",
      "Processing 5f87a1a03.png...\n",
      "Processing a04fa8d0e.png...\n",
      "Processing 3239a3103.png...\n",
      "Processing 21aca4703.png...\n",
      "Processing a0c3ac10d.png...\n",
      "Processing 2662a1c0c.png...\n",
      "Processing 35aeaf904.png...\n",
      "Processing b381abd01.png...\n",
      "Processing 3ffcaf60d.png...\n",
      "Processing ac56ad408.png...\n",
      "Processing 946ba8f02.png...\n",
      "Processing 6a7ea6007.png...\n",
      "Processing aac3a9d05.png...\n",
      "Processing 23c2a920f.png...\n",
      "Processing 1b1aa910b.png...\n",
      "Processing e28fa1d04.png...\n",
      "Processing abf3ae50f.png...\n",
      "Processing e19cab606.png...\n",
      "Processing 005baa303.png...\n",
      "Processing 0446afa04.png...\n",
      "Processing 1df8a3b02.png...\n",
      "Processing 0ae9acf03.png...\n",
      "Processing 216bada00.png...\n",
      "Processing 29a0a6b09.png...\n",
      "Processing 3ff6afa0a.png...\n",
      "Processing c423a7003.png...\n",
      "Processing 08cdaa90d.png...\n",
      "Processing c926ade0d.png...\n",
      "Processing 06f4a7808.png...\n",
      "Processing 6a23a1003.png...\n",
      "Processing dd42a1409.png...\n",
      "Processing 4264ad809.png...\n",
      "Processing f3e7a580f.png...\n",
      "Processing a534a9403.png...\n",
      "Processing 9836a3c06.png...\n",
      "Processing 6aaea2c03.png...\n",
      "Processing 8f09ad904.png...\n",
      "Processing 2c25aee0b.png...\n",
      "Processing 289ea2902.png...\n",
      "Processing 8d49a7806.png...\n",
      "Processing bfedaa10c.png...\n",
      "Processing d3e9aa209.png...\n",
      "Processing 6266a1208.png...\n",
      "Processing 78dda1704.png...\n",
      "Processing 74d9ab306.png...\n",
      "Processing 3038a5107.png...\n",
      "Processing 3465acf04.png...\n",
      "Processing 3767ac40e.png...\n",
      "Processing 1f15a440a.png...\n",
      "Processing 0f16af10a.png...\n",
      "Processing cc59acd0c.png...\n",
      "Processing 09a6a080e.png...\n",
      "Processing 759eab40b.png...\n",
      "Processing 5f73ab90c.png...\n",
      "Processing 98e8a070b.png...\n",
      "Processing 6d06a2309.png...\n",
      "Processing 1fb6afe05.png...\n",
      "Processing a37eab70b.png...\n",
      "Processing 3e2ca6d03.png...\n",
      "Processing b2f6a2608.png...\n",
      "Processing a786ad803.png...\n",
      "Processing 953cad706.png...\n",
      "Processing 3d9ea1609.png...\n",
      "Processing e4afa5103.png...\n",
      "Processing 7da3ada02.png...\n",
      "Processing c999a3005.png...\n",
      "Processing 621ca0101.png...\n",
      "Processing 18bea840e.png...\n",
      "Processing 549aa1c02.png...\n",
      "Processing fbc2aa104.png...\n",
      "Processing cc36a4603.png...\n",
      "Processing 0050a3803.png...\n",
      "Processing 6327a920c.png...\n",
      "Processing d04eaf400.png...\n",
      "Processing 57c4a1606.png...\n",
      "Processing 00b6aee0f.png...\n",
      "Processing 7249a8a05.png...\n",
      "Processing df58aac03.png...\n",
      "Processing afaaae508.png...\n",
      "Processing a035a860e.png...\n",
      "Processing c05aad701.png...\n",
      "Processing d585ae007.png...\n",
      "Processing 2302a2303.png...\n",
      "Processing dc7aabd0b.png...\n",
      "Processing 75aeab201.png...\n",
      "Processing 4954acb0d.png...\n",
      "Processing 5d9da8906.png...\n",
      "Processing ea23aa80d.png...\n",
      "Processing 1118a180a.png...\n",
      "Processing 0bb7ade08.png...\n",
      "Processing 489da4705.png...\n",
      "Processing b9ffa3107.png...\n",
      "Processing 1022ac105.png...\n",
      "Processing 3ac4a4c0d.png...\n",
      "Processing 4209a540c.png...\n",
      "Processing 1176acf0f.png...\n",
      "Processing 3565ac504.png...\n",
      "Processing 09d0a0800.png...\n",
      "Processing 1c0facd06.png...\n",
      "Processing 94ada2c0b.png...\n",
      "Processing 500ba800a.png...\n",
      "Processing 1361a4803.png...\n",
      "Processing db30a5008.png...\n",
      "Processing fed9a0602.png...\n",
      "Processing 1896a610c.png...\n",
      "Processing 30a1a6605.png...\n",
      "Processing 355cad30c.png...\n",
      "Processing 22ada5901.png...\n",
      "Processing a40ba440a.png...\n",
      "Processing 1ef8af40f.png...\n",
      "Processing 8831ad60e.png...\n",
      "Processing ae00ad500.png...\n",
      "Processing 9deea0108.png...\n",
      "Processing bbb2ae004.png...\n",
      "Processing d174afb0d.png...\n",
      "Processing 5e4daee0d.png...\n",
      "Processing 2a5ba9d08.png...\n",
      "Processing bc10a3200.png...\n",
      "Processing 4c75a2a0c.png...\n",
      "Processing acd8a9403.png...\n",
      "Processing 433eaa30f.png...\n",
      "Processing 0bccae309.png...\n",
      "Processing ffa4a1105.png...\n",
      "Processing 4264ad50e.png...\n",
      "Processing 3459a1d0f.png...\n",
      "Processing 89f0aca04.png...\n",
      "Processing 7988a2805.png...\n",
      "Processing baffa780f.png...\n",
      "Processing d603aa004.png...\n",
      "Processing a840ab000.png...\n",
      "Processing 3dcfa9409.png...\n",
      "Processing 8842a410b.png...\n",
      "Processing 97daaa509.png...\n",
      "Processing e0a8a6c0b.png...\n",
      "Processing 8cf3ad307.png...\n",
      "Processing 73ddafa00.png...\n",
      "Processing 04c9a9301.png...\n",
      "Processing 7210ab205.png...\n",
      "Processing 085dabc0e.png...\n",
      "Processing 3418a3a01.png...\n",
      "Processing 08faa1a06.png...\n",
      "Processing d13aad706.png...\n",
      "Processing f1f9ab900.png...\n",
      "Processing 3797a1a04.png...\n",
      "Processing a301a3d0c.png...\n",
      "Processing c9e0a8b04.png...\n",
      "Processing a307a2508.png...\n",
      "Processing 68a3a6b07.png...\n",
      "Processing 47aaa020a.png...\n",
      "Processing a04aadd02.png...\n",
      "Processing ca34ada0b.png...\n",
      "Processing f081a7b0d.png...\n",
      "Processing 6cd1acd01.png...\n",
      "Processing 18a2a5006.png...\n",
      "Processing 0d4fa4f0a.png...\n",
      "Processing 9db0aa801.png...\n",
      "Processing 5079aa00f.png...\n",
      "Processing b5e1a7603.png...\n",
      "Processing a5b1a6305.png...\n",
      "Processing 2e25a0403.png...\n",
      "Processing 6054a8707.png...\n",
      "Processing 6850a1401.png...\n",
      "Processing 6495a3f09.png...\n",
      "Processing df7da1109.png...\n",
      "Processing 510faba09.png...\n",
      "Processing 7e8ca9d00.png...\n",
      "Processing 4a0da8b04.png...\n",
      "Processing 0bcfa9a07.png...\n",
      "Processing c01ea7e05.png...\n",
      "Processing d3c7ad403.png...\n",
      "Processing 7790aac02.png...\n",
      "Processing b9a3a820f.png...\n",
      "Processing 1e50a1103.png...\n",
      "Processing 3196a7b0f.png...\n",
      "Processing a25facc05.png...\n",
      "Processing ff93afc07.png...\n",
      "Processing 41daa2907.png...\n",
      "Processing 905aae302.png...\n",
      "Processing e364ace05.png...\n"
     ]
    }
   ],
   "source": [
    "tds = PlantSeedlingTestDataset(\"data/plant-seedling-test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ac53b063-553e-4325-b672-42b6d7a3202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_test = DataLoader(tds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e61f09a2-ad2f-40f4-8e42-e213cc42f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def save_result(model, loader):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
    "    result = []\n",
    "    for x in loader:\n",
    "        x_var = Variable(x.type(gpu_dtype))\n",
    "\n",
    "        scores = model(x_var)\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        result += preds\n",
    "\n",
    "    classifications = [ds.labels[int(num)] for num in result]\n",
    "    df = pd.DataFrame({\"file\": tds.images, \"species\": classifications})\n",
    "    df = df.sort_values([\"file\"])\n",
    "    df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0371f0a1-8356-4940-8bfb-d767a1e59945",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(model, loader_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
